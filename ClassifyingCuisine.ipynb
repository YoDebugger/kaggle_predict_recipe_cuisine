{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c1a412b-4535-46d5-8fe3-e8600801817a",
    "_uuid": "4e6801037e5274668f0b8667591d41c1abbe8be1"
   },
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "00d2aeb7-f5f6-407f-9a93-3bd76a6a07ff",
    "_uuid": "e88af6df71dc71c31208047b965ac30cdbf39729"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "recipeRaw = pd.read_json(\"kaggle/train_refined.json\")\n",
    "recipeRaw[\"ingredientsFlat\"] = recipeRaw[\"ingredients\"].apply(lambda x: ' '.join(x))\n",
    "recipeRaw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e1f7eab-ffa0-446a-9c34-daae03c16379",
    "_uuid": "1db441bec8a629339122deb853f4757a7f5c8df7"
   },
   "outputs": [],
   "source": [
    "recipeRawTest = pd.read_json(\"kaggle/test.json\")\n",
    "recipeRawTest[\"ingredientsFlat\"] = recipeRawTest[\"ingredients\"].apply(lambda x: ' '.join(x))\n",
    "testdocs = recipeRawTest[\"ingredientsFlat\"].values\n",
    "recipeRawCombined = recipeRaw.append(recipeRawTest)\n",
    "recipeRawCombined[40000:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a5b844ba-7eb5-4a22-a396-5e23eb23cd85",
    "_uuid": "5ad902e961a68cd09c05269696439abf9d0f8654"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(recipeRaw[\"cuisine\"].values)\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29a5542b-848b-4428-9217-2000a859a4dc",
    "_uuid": "499cd7566059f69ee184d2e0bb56c58274d7bf8f"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "docs = recipeRaw[\"ingredientsFlat\"].values\n",
    "testdocs = recipeRawTest[\"ingredientsFlat\"].values\n",
    "docsCombined = recipeRawCombined[\"ingredientsFlat\"].values\n",
    "labels_enc = le.transform(recipeRaw[\"cuisine\"].values)\n",
    "labels = to_categorical(labels_enc)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7bcf422f-0e75-4d49-b3b1-12553fcaf4ff",
    "_uuid": "46b7fc9aef5a519f96a295e980ba15deee781e97",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docsCombined)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "encoded_test_docs = t.texts_to_sequences(testdocs)\n",
    "print(vocab_size)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 40\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "print(len(padded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9182c6ea-cd7d-46a1-bd29-a532e0935474",
    "_uuid": "31ef8ec3a8d8a6229dc767a90061dfc50294b456"
   },
   "outputs": [],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "97ec3b51-53be-4078-a72a-a4222d2ffac0",
    "_uuid": "72b42e2a27337810e4604db0f67d626a62008854"
   },
   "outputs": [],
   "source": [
    "vocab = pd.DataFrame.from_dict(t.word_index,orient=\"index\")\n",
    "vocab.drop([0],axis=1).reset_index().rename(columns={\"index\":\"word\"}).to_csv(\"vocab.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fa875535-7cef-40da-9add-dfe1d51395b0",
    "_uuid": "befd8941982ee2119daa0b9cc6b10a1e14656239"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "593bfd0a-b703-4e87-96dd-a7eb98e6940e",
    "_uuid": "f71c5f0b731d3418d3cb83be758233b5030da29d"
   },
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "890c0395-03d7-4608-b540-8ec2401b96a2",
    "_uuid": "225c77061e58aa23140df026385bf7cbc02e58e7"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 88\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold.split(padded_docs, labels):\n",
    "    # define the model\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=40, trainable=False))\n",
    "    model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    #model.add(Dense(le.classes_.size, activation='sigmoid'))\n",
    "    model.add(Dense(le.classes_.size, activation='softmax'))\n",
    "    # compile the model\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy]\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    if cvscores == []:\n",
    "        print(model.summary())\n",
    "    # fit the model\n",
    "    model.fit(padded_docs[train], labels[train], epochs=5, verbose=0)\n",
    "    scores = model.evaluate(padded_docs[test], labels[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cade4e3e-0feb-4cd1-9dfb-3c7f090b7b44",
    "_uuid": "caaa007d8244b9f7fcd765aa413d248a603fac67"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(padded_test_docs)\n",
    "print(predictions.shape)\n",
    "#print(predictions)\n",
    "recipeRawTest[\"cuisine\"] = [le.classes_[np.argmax(prediction)] for prediction in predictions]\n",
    "recipeRawTest.head()\n",
    "recipeRawTest.drop([\"ingredients\",\"ingredientsFlat\"],axis=1).to_csv(\"kaggle/submission.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, Layout\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "\n",
    "outputText = widgets.Text()\n",
    "inputText = widgets.Text()\n",
    "\n",
    "# test url: https://kitchenstories.io/en/recipes/grilled-steak-salad\n",
    "\n",
    "textarea = widgets.Textarea(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='Input:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%', height='300px')\n",
    ")\n",
    "\n",
    "output_textarea = widgets.Textarea(\n",
    "    value='Output Area',\n",
    "    placeholder='Type something',\n",
    "    description='Output:',\n",
    "    disabled=False,\n",
    "    layout=Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    border='solid',\n",
    "                    width='auto')\n",
    ")\n",
    "\n",
    "def filter_text(in_text):\n",
    "    text = in_text\n",
    "    text = text.split('\\n')\n",
    "    lines = text\n",
    "    for i, l in enumerate(lines):\n",
    "         if '\\t' in l:\n",
    "                index = l.find('\\t')\n",
    "                lines[i] = l[index:]\n",
    "    \n",
    "    for i, l in enumerate(lines):\n",
    "         lines[i] = l.lower().replace('for serving', '').replace('for frying', '').strip()\n",
    "    # text = '\\n'.join(lines)\n",
    "    return lines\n",
    "\n",
    "def buttonHandler(sender):\n",
    "    intext = textarea.value.upper()\n",
    "    outext = filter_text(intext)\n",
    "    #print(outext)\n",
    "    content = [{'ingredients':outext}]\n",
    "    path_gui_ingredient_input = 'gui_ingredient_test_input.json'\n",
    "    json_data_ = json.dumps(content,indent=4,sort_keys=True, ensure_ascii=False)\n",
    "    with open(path_gui_ingredient_input, 'w') as f:\n",
    "        f.write(json_data_)\n",
    "    pred1,prob1,pred2,prob2 = testit(path_gui_ingredient_input)\n",
    "    #print pred1,prob1,pred2,prob2\n",
    "    output_textarea.value = pred1 + \" : \" + str(int(prob1)) + \" %\\n\" + pred2 + \" : \" + str(int(prob2)) + \" %\"\n",
    "\n",
    "def makeUpperCase(sender):\n",
    "    outputText.value = inputText.value.upper()\n",
    "\n",
    "def testit(path_gui_ingredient_input):\n",
    "    recipeRawTest = pd.read_json(path_gui_ingredient_input)\n",
    "    recipeRawTest[\"ingredientsFlat\"] = recipeRawTest[\"ingredients\"].apply(lambda x: ' '.join(x))\n",
    "    testdocs = recipeRawTest[\"ingredientsFlat\"].values\n",
    "    encoded_test_docs = t.texts_to_sequences(testdocs)\n",
    "    padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "    predictions = model.predict(padded_test_docs)\n",
    "    #print(predictions.shape)\n",
    "\n",
    "    for prediction in predictions:\n",
    "        #print prediction\n",
    "        #print np.argmax(prediction)\n",
    "        idx = prediction.argsort()[-2:][::-1]\n",
    "        #print le.classes_[idx[0]], prediction[idx[0]]*100, le.classes_[idx[1]], prediction[idx[1]]*100\n",
    "        return le.classes_[idx[0]], prediction[idx[0]]*100, le.classes_[idx[1]], prediction[idx[1]]*100\n",
    "        #return le.classes_[np.argmax(prediction)]\n",
    "\n",
    "    #recipeRawTest[\"cuisine\"] = [le.classes_[np.argmax(prediction)] for prediction in predictions]\n",
    "    #print recipeRawTest[\"cuisine\"][0]\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Magical Predicton',\n",
    "    disabled=False,\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Predict',\n",
    ")\n",
    "button.on_click(buttonHandler)\n",
    "inputText.on_submit(makeUpperCase)\n",
    "# VBox([inputText, outputText, textarea, button, output_textarea])\n",
    "HBox([textarea, VBox([button, output_textarea])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
