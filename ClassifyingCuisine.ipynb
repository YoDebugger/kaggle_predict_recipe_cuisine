{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4c1a412b-4535-46d5-8fe3-e8600801817a",
    "_uuid": "4e6801037e5274668f0b8667591d41c1abbe8be1"
   },
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "00d2aeb7-f5f6-407f-9a93-3bd76a6a07ff",
    "_uuid": "e88af6df71dc71c31208047b965ac30cdbf39729"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredientsFlat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish and portuguese</td>\n",
       "      <td>42779</td>\n",
       "      <td>[olive oil, salt, medium shrimp, pepper, garli...</td>\n",
       "      <td>olive oil salt medium shrimp pepper garlic cho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cuisine     id  \\\n",
       "0                   greek  10259   \n",
       "1                american  25693   \n",
       "2                  indian  22213   \n",
       "3                  indian  13162   \n",
       "4  spanish and portuguese  42779   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2                [water, vegetable oil, wheat, salt]   \n",
       "3  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "4  [olive oil, salt, medium shrimp, pepper, garli...   \n",
       "\n",
       "                                     ingredientsFlat  \n",
       "0  romaine lettuce black olives grape tomatoes ga...  \n",
       "1  plain flour ground pepper salt tomatoes ground...  \n",
       "2                     water vegetable oil wheat salt  \n",
       "3  black pepper shallots cornflour cayenne pepper...  \n",
       "4  olive oil salt medium shrimp pepper garlic cho...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "recipeRaw = pd.read_json(\"kaggle/train_refined.json\")\n",
    "recipeRaw[\"ingredientsFlat\"] = recipeRaw[\"ingredients\"].apply(lambda x: ' '.join(x))\n",
    "recipeRaw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0e1f7eab-ffa0-446a-9c34-daae03c16379",
    "_uuid": "1db441bec8a629339122deb853f4757a7f5c8df7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baking_time</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredientsFlat</th>\n",
       "      <th>name</th>\n",
       "      <th>preparation_time</th>\n",
       "      <th>resting_time</th>\n",
       "      <th>steps</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [baking_time, cuisine, difficulty, id, ingredients, ingredientsFlat, name, preparation_time, resting_time, steps, uuid]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipeRawTest = pd.read_json(\"kaggle/test.json\")\n",
    "recipeRawTest[\"ingredientsFlat\"] = recipeRawTest[\"ingredients\"].apply(lambda x: ' '.join(x))\n",
    "testdocs = recipeRawTest[\"ingredientsFlat\"].values\n",
    "recipeRawCombined = recipeRaw.append(recipeRawTest)\n",
    "recipeRawCombined[40000:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "a5b844ba-7eb5-4a22-a396-5e23eb23cd85",
    "_uuid": "5ad902e961a68cd09c05269696439abf9d0f8654"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'american',\n",
       " u'british',\n",
       " u'chinese',\n",
       " u'french',\n",
       " u'greek',\n",
       " u'indian',\n",
       " u'italian',\n",
       " u'japanese',\n",
       " u'korean',\n",
       " u'mexican',\n",
       " u'spanish and portuguese',\n",
       " u'thai',\n",
       " u'vietnamese']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(recipeRaw[\"cuisine\"].values)\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "29a5542b-848b-4428-9217-2000a859a4dc",
    "_uuid": "499cd7566059f69ee184d2e0bb56c58274d7bf8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "docs = recipeRaw[\"ingredientsFlat\"].values\n",
    "testdocs = recipeRawTest[\"ingredientsFlat\"].values\n",
    "docsCombined = recipeRawCombined[\"ingredientsFlat\"].values\n",
    "labels_enc = le.transform(recipeRaw[\"cuisine\"].values)\n",
    "labels = to_categorical(labels_enc)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "7bcf422f-0e75-4d49-b3b1-12553fcaf4ff",
    "_uuid": "46b7fc9aef5a519f96a295e980ba15deee781e97",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3029\n",
      "34503\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docsCombined)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "encoded_test_docs = t.texts_to_sequences(testdocs)\n",
    "print(vocab_size)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 40\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "print(len(padded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "9182c6ea-cd7d-46a1-bd29-a532e0935474",
    "_uuid": "31ef8ec3a8d8a6229dc767a90061dfc50294b456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "97ec3b51-53be-4078-a72a-a4222d2ffac0",
    "_uuid": "72b42e2a27337810e4604db0f67d626a62008854"
   },
   "outputs": [],
   "source": [
    "vocab = pd.DataFrame.from_dict(t.word_index,orient=\"index\")\n",
    "vocab.drop([0],axis=1).reset_index().rename(columns={\"index\":\"word\"}).to_csv(\"vocab.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "fa875535-7cef-40da-9add-dfe1d51395b0",
    "_uuid": "befd8941982ee2119daa0b9cc6b10a1e14656239"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "593bfd0a-b703-4e87-96dd-a7eb98e6940e",
    "_uuid": "f71c5f0b731d3418d3cb83be758233b5030da29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3029, 100)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "890c0395-03d7-4608-b540-8ec2401b96a2",
    "_uuid": "225c77061e58aa23140df026385bf7cbc02e58e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 100)           302900    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 100)           30100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               500250    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                3263      \n",
      "=================================================================\n",
      "Total params: 836,513\n",
      "Trainable params: 533,613\n",
      "Non-trainable params: 302,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "acc: 96.28%\n",
      "acc: 96.26%\n",
      "acc: 96.28%\n",
      "acc: 96.52%\n",
      "acc: 96.36%\n",
      "96.34% (+/- 0.10%)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold.split(padded_docs, labels):\n",
    "    # define the model\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=40, trainable=False))\n",
    "    model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(le.classes_.size, activation='sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    # summarize the model\n",
    "    if cvscores == []:\n",
    "        print(model.summary())\n",
    "    # fit the model\n",
    "    model.fit(padded_docs[train], labels[train], epochs=5, verbose=0)\n",
    "    scores = model.evaluate(padded_docs[test], labels[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "cade4e3e-0feb-4cd1-9dfb-3c7f090b7b44",
    "_uuid": "caaa007d8244b9f7fcd765aa413d248a603fac67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(807, 13)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(padded_test_docs)\n",
    "print(predictions.shape)\n",
    "#print(predictions)\n",
    "recipeRawTest[\"cuisine\"] = [le.classes_[np.argmax(prediction)] for prediction in predictions]\n",
    "recipeRawTest.head()\n",
    "recipeRawTest.drop([\"ingredients\",\"ingredientsFlat\"],axis=1).to_csv(\"kaggle/submission.csv\",index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
